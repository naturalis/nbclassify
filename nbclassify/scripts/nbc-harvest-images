#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Image harvester for downloading photos with meta data from Flickr.

The following subcommands are available:

* harvest: Harvest images from a Flickr account.
* cleanup: Remove image files from a local directory and its subdirectories
  for which the filename is a Flickr photo ID and the photo ID does not exist
  on the Flickr account.

See the --help option for any of these subcommands for more information.
"""

import argparse
import datetime
import hashlib
import logging
import mimetypes
import os
import re
import sys
import time
import urllib
import urllib2
import xml.etree.ElementTree

import flickrapi

import nbclassify.db as db

# Workaround for flickrapi issue #24
# https://bitbucket.org/sybren/flickrapi/issue/24/
try:
    logging.root.handlers.pop()
except IndexError:
    # Once the bug is fixed in the library the handlers list will be empty,
    # so we need to catch this error.
    pass

# Flickr API Key for NBClassify.
FLICKR_API_KEY = "6ad8fc70959e3c50eff8339287dd38bd"
FLICKR_API_SECRET = "d7e3a0b378034fa6"

def main():
    # Create argument parser.
    parser = argparse.ArgumentParser(description='Flickr image harvester')

    parser.add_argument(
        "flickr_uid",
        metavar="FLICKR_UID",
        help="The Flickr user ID to harvest photos from (e.g. 123456789@A12)")
    parser.add_argument(
        "meta_file",
        metavar="FILE",
        help="File name of the meta data file (e.g. meta.db).")
    parser.add_argument(
        "--verbose",
        "-v",
        action='store_const',
        const=True,
        help="Explain what is being done.")

    subparsers = parser.add_subparsers(
        help="Specify which task to start.",
        dest='task'
    )

    help_harvest = "Download images with meta data from a Flickr account."
    parser_harvest = subparsers.add_parser(
        'harvest',
        help=help_harvest,
        description=help_harvest
    )
    parser_harvest.add_argument(
        "--tags",
        metavar="TAGS",
        help="A comma-delimited list of complete tags. Photos with the tags listed "\
        "will be harvested. You can exclude results that match a tag by " \
        "prepending it with a _ character (e.g. 'foo:yes,_bar:no').")
    parser_harvest.add_argument(
        "--tag_mode",
        metavar="MODE",
        default='all',
        help="Either 'any' for an OR combination of tags, or 'all' for an " \
        "AND combination. Defaults to 'all' if not specified.")
    parser_harvest.add_argument(
        "--tag_keys",
        metavar="KEYS",
        help="A comma-delimited list of tag-keys (tag = <key>:<value>). "\
        "Photos with the given keys in the tags, but variable values will be harvested.")
    parser_harvest.add_argument(
        "--key_mode",
        metavar="MODE",
        default="all",
        choices=['all', 'any'],
        help="Either 'any' for an OR combination of tag-keys, or 'all' for an "\
        "AND combination. Defaults to 'all' if not specified.")
    parser_harvest.add_argument(
        "--page",
        metavar="N",
        default=1,
        type=int,
        help="The first pagenumber of results to return. If this argument is omitted, " \
        "it defaults to 1.")
    parser_harvest.add_argument(
        "--pages",
        metavar="N",
        default=1,
        type=int,
        help="The number of pages to harvest images from. If this argument is "\
        "omitted, it defaults to 1. To harvest from all pages, use 0.")
    parser_harvest.add_argument(
        "--per_page",
        metavar="N",
        default=100,
        type=int,
        help="Number of photos to return per page. If this argument is " \
        "omitted, it defaults to 100. The maximum allowed value is 500.")
    parser_harvest.add_argument(
        "--save_mode",
        metavar="MODE",
        default='g-s',
        choices=['all', 'g-s'],
        help="Mode of how to save the images: only Genus-species directories (g-s) "\
        "or all possible levels of taxonomy (all). Defaults to Genus-species if "\
        "omitted.")
    parser_harvest.add_argument(
        "imdir",
        metavar="PATH",
        help="Base directory where the Flickr harvested images will be stored.")

    help_cleanup = """Clean up your local archive of Flickr harvested images.
    Images that were harvested, but were later removed from Flickr, will also
    be deleted from your local archive."""
    parser_cleanup = subparsers.add_parser(
        'cleanup',
        help=help_cleanup,
        description=help_cleanup
    )
    parser_cleanup.add_argument(
        "imdir",
        metavar="PATH",
        help="Base directory where the Flickr harvested images are stored.")

    # Parse arguments.
    args = parser.parse_args()

    # Print debug messages if the -d flag is set for the Python interpreter.
    if sys.flags.debug:
        log_level = logging.DEBUG
    elif args.verbose:
        log_level = logging.INFO
    else:
        log_level = logging.WARNING

    logging.basicConfig(level=log_level, format='%(levelname)s %(message)s')

    # Get path to meta data file.
    meta_path = os.path.join(args.imdir, args.meta_file)

    # Make the image directory path absolute.
    args.imdir = os.path.realpath(args.imdir)
    
    # Set correct meta data file for database.
    db.conf.meta_file = args.meta_file
        
    # Set correct required ranks for database
    ranks = ('domain', 'kingdom', 'phylum', 'class', 'order', 'family', 
        'subfamily', 'tribus', 'genus', 'subgenus', 'section', 'species', 'subspecies')
    required_ranks = []
    if args.tag_keys:
        for key in args.tag_keys.strip().split(","):
            if key in ranks:
                required_ranks.append(key)
    db.conf.required_ranks = tuple(required_ranks)
    
    start = datetime.datetime.now().replace(microsecond=0)
    sys.stderr.write("Start at: %s\n" % start)

    if args.task == 'harvest':
        harvest(meta_path, args)
    elif args.task == 'cleanup':
        cleanup(meta_path, args)
    
    end = datetime.datetime.now().replace(microsecond=0)
    sys.stderr.write("Finished at: %s\n" % end)
    sys.stderr.write("Duration: %s\n" % (end-start))

def harvest(meta_path, args):
    """Run the image harvester."""
    if not (0 < args.per_page <= 500):
        sys.stderr.write("Incorrect value for option --per_page\n")
        return

    # Initialize Flickr downloader.
    flickr = FlickrDownloader(FLICKR_API_KEY, FLICKR_API_SECRET, args.flickr_uid)

    # Flickr search options.
    search_options = {}
    if args.tag_mode is not None: search_options['tag_mode'] = args.tag_mode
    if args.tags is not None:
        # We have to do this because the argparse module parses strings that
        # start with a hyphen (-) as a command line option.
        search_options['tags'] = args.tags.replace('_', '-')
    if args.page is not None: search_options['page'] = args.page
    if args.per_page is not None: search_options['per_page'] = args.per_page

    # Create a new database if required.
    db_dir = os.path.dirname(meta_path)
    if not os.path.exists(db_dir):
        os.makedirs(db_dir)
    if not os.path.isfile(meta_path):
        db.make_meta_db(meta_path)

    with db.session_scope(meta_path) as (session, metadata):
        # Download and organize photos.
        harvester = ImageHarvester(flickr, session, metadata)
        n = harvester.archive_taxon_photos(args.imdir, args, **search_options)
        if n > 0:
            sys.stderr.write("Finished processing %d photos\n" % n)
        else:
            sys.stderr.write("No photos were found matching your search criteria\n")

def cleanup(meta_path, args):
    """Clean up image directory."""
    flickr = FlickrDownloader(FLICKR_API_KEY, FLICKR_API_SECRET, args.flickr_uid)
    with db.session_scope(meta_path) as (session, metadata):
        harvester = ImageHarvester(flickr, session, metadata)
        sys.stderr.write("Now checking for unknown Flickr photos in `%s` " % args.imdir)
        n = harvester.remove_unknown_photos(args.imdir)
        sys.stderr.write("A total of %d photos were deleted\n" % n)


class ImageHarvester(object):

    """Harvest images from a Flickr account."""

    def __init__(self, flickr, session, metadata):
        """Initialize the image harvester.

        Expects a FlickrDownloader instance `flickr`, and a connection to an
        existing metadata database via an SQLAlchemy Session instance
        `sesssion`, and an SQLAlchemy MetaData instance `metadata` which
        describes the database tables.
        """
        self.re_filename_replace = re.compile(r'[\s]+')
        self.re_tags_ignore = re.compile(r'vision:')
        self.re_photo_id = re.compile(r'^[0-9]+$')
        self.re_taxon_tag = re.compile(r'^([a-z_]+):([A-Za-z0-9 ,.\-\(\)=]+)$')
        self.set_flickr_downloader(flickr)
        self.session = session
        self.metadata = metadata

        # Only collect photo taxon information from tags for the following
        # taxonomic ranks.
        self.ranks = ('domain', 'kingdom', 'phylum', 'class', 'order', 'family', 
        'subfamily', 'tribus', 'genus', 'subgenus', 'section', 'species', 'subspecies')

    def set_flickr_downloader(self, flickr):
        """Set the Flickr downloader."""
        if isinstance(flickr, FlickrDownloader):
            self.flickr = flickr
        else:
            raise TypeError("Expected an instance of FlickrDownloader")

    def db_insert_photo(self, photo_info, path, target):
        """Set meta data for a photo in the database.

        Sets the meta data `photo_info` for a photo with file path `path` in the
        database, where `path` should be the path constructed from meta data. If
        `path` is not relative from the current directory, `target` should be
        set to the containing directory, which is prepended to `path` to get the
        photo's real path. By default `target` is set to the current directory.

        So if the photo's path is ``/path/to/Genus/Section/species/123.jpg``,
        then `path` should be ``Genus/Section/species/123.jpg`` and `target` is
        ``/path/to/``. Only `path` is stored in the database.

        This function checks whether an existing entry in the database matches
        the file's MD5 hash. If they don't match, the file entry is deleted and
        a new one is created.
        """
        real_path = os.path.join(target, path)
        if not os.path.isfile(real_path):
            raise IOError("Cannot open %s (no such file)" % real_path)
        if not xml.etree.ElementTree.iselement(photo_info):
            raise TypeError("Argument `photo_info` is not an xml.etree.ElementTree element")

        # Photo ID must be an integer.
        photo_id = int(photo_info.get('id'))

        # Get photo metadata.
        title = photo_info.find('title')
        title = None if title is None else title.text
        description = photo_info.find('description')
        description = None if description is None else description.text
        tags = self.flickr_info_get_tags(photo_info)
        taxa, seen = self.get_taxa_from_tags(tags)

        # Insert the photo into the database.
        db.insert_new_photo(self.session, self.metadata,
            target,
            path,
            update=True,
            id=photo_id,
            title=title,
            description=description,
            tags=tags,
            taxa=taxa
        )

    def archive_taxon_photos(self, target, args, **filters):
        """Download photos with taxon tags to a taxonomic directory hierarchy.

        Taxon photos are photos with tags with taxonomic information of the
        format ``rank:name``.

        Downloads photos matching Flickr API search criteria set as remaining
        keyword arguments. Downloaded photos are stored in a taxonomic 
        directory structure like: ``Genus/Section/species`` in the target
        directory `target`. Photo metadata is automatically stored in a
        database.

        Returns the number of photos processed.
        """
        if not os.path.isdir(target):
            raise IOError("Cannot open %s (no such directory)" % target)
        
        pagenr = args.page
        last_page = args.page + 1
        downloaded = 0
        
        # Loop through flickr pages.
        while pagenr < last_page:
            filters['page'] = pagenr
            photos = self.flickr.execute('photos.search', **filters)
          
            if photos is False:
                raise RuntimeError("Failed to obtain photo list from Flickr")
            
            n_photos = len(photos)
            if n_photos > 0:
                sys.stderr.write("Going to process %s photos on page %d...\n" % (n_photos, pagenr))

            # Download each photo and set meta data in the database.
            for n, photo in enumerate(photos, start=1):
                if (n+1) % 10 == 0:
                    sys.stderr.write("Processing photo %d/%d...\n" % ((n+1), n_photos))
                photo_id = int(photo.get('id'))
                info = self.flickr.execute('photos.getInfo', photo_id=photo_id)
                if info is False:
                    raise RuntimeError("Failed to obtain photo info from Flickr")
    
                # Get some photo metadata.
                title = info.find('title')
                title = None if title is None else title.text
                tags = self.flickr_info_get_tags(info)
                taxa, seen = self.get_taxa_from_tags(tags)
                ext = info.get('originalformat')
                
                save = self.check_required_keys(seen, args.tag_keys, args.key_mode)
                if save == False:
                    logging.warning("Skipping photo {0} `{1}` because the requested "\
                    "tagkey is not set".format(photo_id, title))
                    continue
    
                # Construct the save path for the photo.
                photo_dir = ""
                if args.save_mode == 'all':
                  save_ranks = self.ranks
                else:
                  save_ranks = ('genus', 'species')
                
                for rank in save_ranks:
                  if rank in taxa:
                    photo_dir = os.path.join(photo_dir, taxa[rank])
    
                filename = "%s.%s" % (photo_id, ext)
                filename = self.re_filename_replace.sub('-', filename)
                photo_path = os.path.join(photo_dir, filename)
    
                real_photo_dir = os.path.join(target, photo_dir)
                real_path = os.path.join(real_photo_dir, filename)
    
                # Check if the folder exists. If not, create it.
                if not os.path.exists(real_photo_dir):
                    logging.info("Creating directory %s", real_photo_dir)
                    os.makedirs(real_photo_dir)
    
                # Download the photo.
                if not os.path.isfile(real_path):
                    logging.info("Downloading photo %s `%s` to %s ...",
                        photo_id, title, real_path)
                    self.flickr.download_photo(photo_id, real_path)
                    downloaded += 1
                else:
                    logging.info("Photo %s `%s` already exists. Skipping download.",
                        photo_id, title)
    
                # Insert the photo into the database.
                self.db_insert_photo(info, photo_path, target)

            
            # Determine only in the first iteration what the last page will be.
            if last_page == args.page + 1:
              if args.pages == 0:
                  for information in photos.iter("photos"):
                      last_page = int(information.get("pages")) + 1
              else:
                  last_page = args.page + args.pages
            
            # Go to the next page
            pagenr += 1

        return downloaded

    def flickr_info_get_tags(self, info):
        """Return a list of the tags from a photo info object."""
        if not xml.etree.ElementTree.iselement(info):
            raise TypeError("Argument `info` is not an xml.etree.ElementTree element")

        out = []
        tags = info.find('tags')
        for tag in tags:
            raw = tag.get('raw').strip()
            out.append(raw)
        return out

    def get_taxa_from_tags(self, tags):
        """Return a taxa dictionary from a list of tags and a list of all tag-keys.

        Searches for tags of the format ``key:value``. If the `key` exists in
        the list of taxonomic ranks `self.ranks`, then this key-value pair will be
        present in the returned taxa dictionary. Every 'key' will be present in the
        returned list.
        """
        taxa = {}
        seen = []
        for tag in tags:
            if self.re_taxon_tag.match(tag):
                rank, taxon = self.re_taxon_tag.search(tag).group(1,2)
                if rank not in seen:
                    seen.append(rank)
                else:
                    logging.warning("Found multiple taxon tags with rank `%s`",
                        ranks)
                if rank not in self.ranks:
                    continue
                taxa[rank] = taxon
        return taxa, seen
        
    def check_required_keys(self, seen, keys, mode):
        """Check if the required keys are set for the photo.
        
        If required tag-keys are given ('keys'), there will be checked
        if all or any (depending on 'mode') of the keys is present
        in the list of seen tag-keys ('seen'). 
        
        Returns False if the requirements are not met, True otherwise.
        """
        if keys:
            for key in keys.strip().split(","):
                if mode == "all" and key not in seen:
                    return False
                elif mode == "any" and key in seen:
                    return True
        return True

    def remove_unknown_photos(self, path):
        """Remove any photos that do not exist on the Flickr account.

        Removes image files from `path` and its subdirectories for which the
        filename is a Flickr photo ID and the photo ID does not exist on
        the Flickr account.

        Returns the number of photos that were removed.
        """
        n = 0
        for root, dirs, files in os.walk(path, topdown=False):
            for name in files:
                im_path = os.path.join(root, name)
                mime = mimetypes.guess_type(im_path)[0]
                photo_id, ext = os.path.splitext(name)

                if not mime or not mime.startswith('image'):
                    continue
                if not self.re_photo_id.match(photo_id):
                    continue

                try:
                    perms = self.flickr.execute('photos.getPerms', photo_id=photo_id)
                    sys.stderr.write('.')
                except flickrapi.exceptions.FlickrError as e:
                    if "Photo not found" in str(e):
                        try:
                            os.remove(im_path)
                            sys.stderr.write("\nRemoved photo `%s`\n" % im_path)
                            n += 1
                        except:
                            sys.stderr.write("\nERROR: Failed to remove photo `%s`\n" % im_path)
                    else:
                        raise

        sys.stderr.write('\n')
        return n

class FlickrDownloader(object):

    """Download photos with metadata from Flickr."""

    def __init__(self, key, secret, uid):
        self.key = key
        self.secret = secret
        self.uid = uid
        self.token = None
        self.frob = None
        self.api = flickrapi.FlickrAPI(key, secret, format='etree')
        self.api.authenticate_via_browser(perms='write')
        """
        # Flickr's two-phase authentication.
        self.token, self.frob = self.api.get_token_part_one(perms='read')

        if self.token:
            # We have a token, but it might not be valid.
            sys.stderr.write("Flickr token found\n")
            try:
                self.api.auth_checkToken()
            except flickrapi.FlickrError:
                self.token = None

        if not self.token:
            # No valid token, so redirect to Flickr.
            sys.stderr.write("Please authorize this program via Flickr. Redirecting to Flickr...\n")
            raw_input("Press ENTER after you authorized this program")

        self.api.get_token_part_two((self.token, self.frob))
        """
        sys.stderr.write("Flickr authorization success\n")

    def execute(self, method, *args, **kwargs):
        """Execute a method of the Flickr API.

        The method name `method` can be followed by the method specific
        arguments. Returns the result or True on success, False otherwise.

        The Flickr method arguments `api_key` and `user_id` are automatically
        added and can be omitted when calling this method.
        """
        #if self.token is None:
        #    raise RuntimeError("Flickr token not set")
        if not isinstance(method, str):
            raise TypeError("Argument `method` must be a string")
        try:
            meth = method.replace('.', '_')
            meth = re.sub("^flickr_", "", meth)
            meth = getattr(self.api, meth)
        except AttributeError:
            raise AttributeError("Flickr API method `%s` not found" % method)

        for tries in range(4):
            try:
                rsp = meth(api_key=self.key, user_id=self.uid, *args, **kwargs)
                break
            except urllib2.HTTPError:
                # The Flickr server sometimes gives HTTP Error 502: Bad
                # Gateway. Try at most 3 times if this error occurs.
                if tries > 2:
                    raise
                time.sleep(3)

        if rsp.get('stat') != 'ok':
            logging.error("Flickr API method `%` failed" % method)
            return False
        if len(rsp) > 0:
            return rsp[0]
        else:
            return True

    def get_photo_urls(self, photo_id):
        """Return the URLs for the photo.

        URLs are returned as a dictionary in the format ``{'label':
        'url', ..}``, where ``label`` is one of the available photo sizes as
        returned by ``flickr.photos.getSizes``.
        """
        urls = {}
        sizes = self.execute('photos.getSizes', photo_id=photo_id)
        if sizes is False:
            raise AttributeError("Failed to get sizes for photo %s" % photo_id)
        for size in sizes:
            label = size.get('label')
            source = size.get('source')
            if label is not None:
                urls[label] = source
        return urls

    def download_photo(self, photo_id, path, size='Original'):
        """Download a photo to a file.

        Downloads the photo with ID `photo_id` and size `size` to a file
        `path`. Returns None if the photo can't be downloaded.
        """
        urls = self.get_photo_urls(photo_id)
        url = urls.get(size)
        if url is None:
            logging.error("No URL found for photo %s with size '%s'" % (photo_id, size))
            return None
        tmpfile = "%s.part" % path
        urllib.urlretrieve(url, tmpfile)
        os.rename(tmpfile, path)

if __name__ == "__main__":
    main()
